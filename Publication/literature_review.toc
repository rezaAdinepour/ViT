\contentsline {chapter}{\numberline {1}BinaryViT \cite {le2023binaryvit}}{4}{chapter.1}%
\contentsline {section}{\numberline {1.1}Introduction}{4}{section.1.1}%
\contentsline {section}{\numberline {1.2}Proposed Model}{4}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Global Average Pooling Layer}{4}{subsection.1.2.1}%
\contentsline {subsection}{\numberline {1.2.2}Multiple Pooling Branches}{5}{subsection.1.2.2}%
\contentsline {subsection}{\numberline {1.2.3}Affine Transformation Before Residual Connections}{5}{subsection.1.2.3}%
\contentsline {subsection}{\numberline {1.2.4}Pyramid Structure}{5}{subsection.1.2.4}%
\contentsline {subsection}{\numberline {1.2.5}Binary Fully-Connected Layers with Enhanced Attention}{6}{subsection.1.2.5}%
\contentsline {subsection}{\numberline {1.2.6}Distillation from Full-Precision Models}{6}{subsection.1.2.6}%
\contentsline {section}{\numberline {1.3}Impact of the Changes}{6}{section.1.3}%
\contentsline {section}{\numberline {1.4}Results and Improvements}{7}{section.1.4}%
\contentsline {subsection}{\numberline {1.4.1}Performance Improvement on ImageNet-1k}{7}{subsection.1.4.1}%
\contentsline {subsection}{\numberline {1.4.2}Efficiency in Terms of Operations and Parameters}{7}{subsection.1.4.2}%
\contentsline {subsection}{\numberline {1.4.3}Comparisons with State-of-the-Art (SOTA) Binary Models}{8}{subsection.1.4.3}%
\contentsline {subsection}{\numberline {1.4.4}Impact of Architectural Enhancements}{8}{subsection.1.4.4}%
\contentsline {subsection}{\numberline {1.4.5}Reduction in Computational Complexity}{8}{subsection.1.4.5}%
\contentsline {subsubsection}{Comparison Between Full-Precision and Binary Versions}{9}{section*.2}%
\contentsline {section}{\numberline {1.5}Overall Improvements}{9}{section.1.5}%
\contentsline {chapter}{\numberline {2}Vision Transformer for Small-Size Datasets \cite {DBLP:journals/corr/abs-2112-13492}}{10}{chapter.2}%
\contentsline {section}{\numberline {2.1}Shifted Patch Tokenization (SPT)}{10}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Previous Approach:}{10}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Proposed Change:}{11}{subsection.2.1.2}%
\contentsline {section}{\numberline {2.2}Locality Self-Attention (LSA)}{11}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Previous Approach:}{11}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Proposed Change:}{11}{subsection.2.2.2}%
\contentsline {section}{\numberline {2.3}Comparison to Other Data-Efficient ViTs}{12}{section.2.3}%
\contentsline {section}{\numberline {2.4}Efficiency vs. Performance Trade-offs}{13}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Previous Models:}{13}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Proposed Model:}{13}{subsection.2.4.2}%
\contentsline {section}{\numberline {2.5}Performance Gains}{13}{section.2.5}%
\contentsline {section}{\numberline {2.6}Overall Impact of the Proposed Changes}{13}{section.2.6}%
\contentsline {section}{\numberline {2.7}Results and Improvements}{14}{section.2.7}%
\contentsline {subsection}{\numberline {2.7.1}Performance Improvements on Small Datasets}{14}{subsection.2.7.1}%
\contentsline {subsection}{\numberline {2.7.2}Improvements in ImageNet Performance}{14}{subsection.2.7.2}%
\contentsline {subsection}{\numberline {2.7.3}Efficiency and Computational Overhead}{14}{subsection.2.7.3}%
\contentsline {subsection}{\numberline {2.7.4}Ablation Study Results}{15}{subsection.2.7.4}%
\contentsline {subsection}{\numberline {2.7.5}Qualitative Improvements}{15}{subsection.2.7.5}%
\contentsline {subsection}{\numberline {2.7.6}Comparison with State-of-the-Art (SOTA) Models}{15}{subsection.2.7.6}%
\contentsline {section}{\numberline {2.8}Key Takeaways:}{16}{section.2.8}%
\contentsline {chapter}{\numberline {3}How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers \cite {DBLP:journals/corr/abs-2106-10270}}{17}{chapter.3}%
\contentsline {section}{\numberline {3.1}Data Augmentation and Regularization ("AugReg")}{17}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}Previous Works:}{17}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}Proposed Changes}{18}{subsection.3.1.2}%
\contentsline {section}{\numberline {3.2}Trade-offs Between Data, Augmentation, and Compute Budget}{18}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Previous Works:}{18}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Proposed Changes:}{18}{subsection.3.2.2}%
\contentsline {section}{\numberline {3.3}Regularization Techniques and Their Impact}{19}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Previous Works:}{19}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Proposed Changes:}{19}{subsection.3.3.2}%
\contentsline {section}{\numberline {3.4}Impact of Model Size}{19}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Previous Works:}{19}{subsection.3.4.1}%
\contentsline {subsection}{\numberline {3.4.2}Proposed Changes:}{19}{subsection.3.4.2}%
\contentsline {section}{\numberline {3.5}Pre-training and Transfer Learning}{20}{section.3.5}%
\contentsline {subsection}{\numberline {3.5.1}Previous Works:}{20}{subsection.3.5.1}%
\contentsline {subsection}{\numberline {3.5.2}Proposed Changes:}{20}{subsection.3.5.2}%
\contentsline {section}{\numberline {3.6}Practical Recommendations}{20}{section.3.6}%
\contentsline {section}{\numberline {3.7}Overall Impact of Changes}{20}{section.3.7}%
\contentsline {chapter}{\numberline {4}Training data-efficient image transformers \& distillation through attention \cite {DBLP:journals/corr/abs-2012-12877}}{22}{chapter.4}%
\contentsline {section}{\numberline {4.1}Data-Efficient Image Transformers (DeiT)}{22}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Previous Works:}{22}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Proposed Changes:}{23}{subsection.4.1.2}%
\contentsline {section}{\numberline {4.2}Distillation Through Attention}{23}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Previous Works:}{23}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2}Proposed Changes:}{24}{subsection.4.2.2}%
\contentsline {section}{\numberline {4.3}Smaller and More Efficient Models (DeiT-S and DeiT-Ti)}{24}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Previous Works:}{24}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}Proposed Changes:}{24}{subsection.4.3.2}%
\contentsline {section}{\numberline {4.4}Performance and Efficiency Gains}{25}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Previous Works:}{25}{subsection.4.4.1}%
\contentsline {subsection}{\numberline {4.4.2}Proposed Changes:}{25}{subsection.4.4.2}%
\contentsline {section}{\numberline {4.5}Transfer Learning and Generalization}{25}{section.4.5}%
\contentsline {subsection}{\numberline {4.5.1}Previous Works:}{26}{subsection.4.5.1}%
\contentsline {subsection}{\numberline {4.5.2}Proposed Changes:}{26}{subsection.4.5.2}%
\contentsline {section}{\numberline {4.6}Results and Improvements}{26}{section.4.6}%
\contentsline {subsection}{\numberline {4.6.1}Competitive Performance with Smaller Datasets}{26}{subsection.4.6.1}%
\contentsline {subsection}{\numberline {4.6.2}Distillation Through Attention Enhances Model Performance}{27}{subsection.4.6.2}%
\contentsline {subsection}{\numberline {4.6.3}Improved Throughput and Computational Efficiency}{27}{subsection.4.6.3}%
\contentsline {subsection}{\numberline {4.6.4}Smaller Models with Comparable Accuracy}{27}{subsection.4.6.4}%
\contentsline {subsection}{\numberline {4.6.5}Transfer Learning and Generalization}{28}{subsection.4.6.5}%
\contentsline {subsection}{\numberline {4.6.6}Training Time Reduction}{28}{subsection.4.6.6}%
\contentsline {subsection}{\numberline {4.6.7}Distillation from CNNs Is More Effective than from Transformers}{28}{subsection.4.6.7}%
\contentsline {section}{\numberline {4.7}Overall Improvements}{29}{section.4.7}%
\contentsline {chapter}{\numberline {5}Going deeper with Image Transformers \cite {DBLP:journals/corr/abs-2103-17239}}{30}{chapter.5}%
\contentsline {section}{\numberline {5.1}Key Ideas:}{30}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Deeper Vision Transformers (ViTs):}{30}{subsection.5.1.1}%
\contentsline {subsection}{\numberline {5.1.2}Class-Attention Mechanism:}{30}{subsection.5.1.2}%
\contentsline {subsection}{\numberline {5.1.3}Distillation with Class-Attention:}{30}{subsection.5.1.3}%
\contentsline {subsection}{\numberline {5.1.4}Efficient Training and Generalization:}{31}{subsection.5.1.4}%
\contentsline {subsection}{\numberline {5.1.5}Performance on Benchmarks:}{31}{subsection.5.1.5}%
\contentsline {section}{\numberline {5.2}Results and Improvements}{31}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Performance Improvement with Depth}{31}{subsection.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2}Introduction of Class-Attention Layers}{31}{subsection.5.2.2}%
\contentsline {subsection}{\numberline {5.2.3}Hard-Label Distillation for Faster Convergence}{32}{subsection.5.2.3}%
\contentsline {subsection}{\numberline {5.2.4}Training Efficiency and Generalization}{32}{subsection.5.2.4}%
\contentsline {subsection}{\numberline {5.2.5}Benchmark Results and Competitive Performance}{32}{subsection.5.2.5}%
\contentsline {subsection}{\numberline {5.2.6}Improved Attention Mechanism for Class Prediction}{33}{subsection.5.2.6}%
\contentsline {chapter}{\numberline {6}Attention is All you need \cite {DBLP:journals/corr/VaswaniSPUJGKP17}}{34}{chapter.6}%
\contentsline {section}{\numberline {6.1}Transformer Architecture:}{34}{section.6.1}%
\contentsline {section}{\numberline {6.2}Self-Attention and Multi-Head Attention:}{34}{section.6.2}%
\contentsline {section}{\numberline {6.3}Positional Encoding:}{35}{section.6.3}%
\contentsline {section}{\numberline {6.4}Advantages of Transformers:}{35}{section.6.4}%
\contentsline {section}{\numberline {6.5}Results:}{35}{section.6.5}%
\contentsline {section}{\numberline {6.6}Summary}{35}{section.6.6}%
