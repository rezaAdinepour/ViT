\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\citation{le2023binaryvit}
\citation{DBLP:journals/corr/abs-2112-13492}
\HyPL@Entry{1<</S/D>>}
\citation{DBLP:journals/corr/abs-2106-10270}
\citation{DBLP:journals/corr/abs-2012-12877}
\citation{DBLP:journals/corr/abs-2103-17239}
\citation{DBLP:journals/corr/VaswaniSPUJGKP17}
\citation{DBLP:journals/corr/abs-2102-11126}
\citation{DBLP:journals/corr/abs-2104-08500}
\citation{zhu2024scalablematmulfreelanguagemodeling}
\citation{zhu2024spikegptgenerativepretrainedlanguage}
\citation{DBLP:journals/corr/abs-2104-01353}
\citation{DBLP:journals/corr/abs-1812-08685}
\citation{maass1997networks}
\citation{DBLP:journals/corr/abs-2004-07532}
\citation{le2023binaryvit}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}BinaryViT \cite  {le2023binaryvit}}{6}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introduction}{6}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Proposed Model}{6}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Global Average Pooling Layer}{6}{subsection.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Multiple Pooling Branches}{7}{subsection.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Affine Transformation Before Residual Connections}{7}{subsection.1.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}Pyramid Structure}{7}{subsection.1.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.5}Binary Fully-Connected Layers with Enhanced Attention}{8}{subsection.1.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.6}Distillation from Full-Precision Models}{8}{subsection.1.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Impact of the Changes}{8}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Results and Improvements}{9}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Performance Improvement on ImageNet-1k}{9}{subsection.1.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Efficiency in Terms of Operations and Parameters}{9}{subsection.1.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.3}Comparisons with State-of-the-Art (SOTA) Binary Models}{10}{subsection.1.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.4}Impact of Architectural Enhancements}{10}{subsection.1.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.5}Reduction in Computational Complexity}{10}{subsection.1.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Comparison Between Full-Precision and Binary Versions}{11}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Overall Improvements}{11}{section.1.5}\protected@file@percent }
\citation{DBLP:journals/corr/abs-2112-13492}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Vision Transformer for Small-Size Datasets \cite  {DBLP:journals/corr/abs-2112-13492}}{12}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Shifted Patch Tokenization (SPT)}{12}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Previous Approach:}{12}{subsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Proposed Change:}{13}{subsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Locality Self-Attention (LSA)}{13}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Previous Approach:}{13}{subsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Proposed Change:}{13}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Comparison to Other Data-Efficient ViTs}{14}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Efficiency vs. Performance Trade-offs}{15}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Previous Models:}{15}{subsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Proposed Model:}{15}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Performance Gains}{15}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Overall Impact of the Proposed Changes}{15}{section.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Results and Improvements}{16}{section.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}Performance Improvements on Small Datasets}{16}{subsection.2.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.2}Improvements in ImageNet Performance}{16}{subsection.2.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.3}Efficiency and Computational Overhead}{16}{subsection.2.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.4}Ablation Study Results}{17}{subsection.2.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.5}Qualitative Improvements}{17}{subsection.2.7.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.6}Comparison with State-of-the-Art (SOTA) Models}{17}{subsection.2.7.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Key Takeaways:}{18}{section.2.8}\protected@file@percent }
\citation{DBLP:journals/corr/abs-2106-10270}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers \cite  {DBLP:journals/corr/abs-2106-10270}}{19}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Data Augmentation and Regularization ("AugReg")}{19}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Previous Works:}{19}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Proposed Changes}{20}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Trade-offs Between Data, Augmentation, and Compute Budget}{20}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Previous Works:}{20}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Proposed Changes:}{20}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Regularization Techniques and Their Impact}{21}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Previous Works:}{21}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Proposed Changes:}{21}{subsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Impact of Model Size}{21}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Previous Works:}{21}{subsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Proposed Changes:}{21}{subsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Pre-training and Transfer Learning}{22}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Previous Works:}{22}{subsection.3.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Proposed Changes:}{22}{subsection.3.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Practical Recommendations}{22}{section.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Overall Impact of Changes}{22}{section.3.7}\protected@file@percent }
\citation{DBLP:journals/corr/abs-2012-12877}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Training data-efficient image transformers \& distillation through attention \cite  {DBLP:journals/corr/abs-2012-12877}}{24}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Data-Efficient Image Transformers (DeiT)}{24}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Previous Works:}{24}{subsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Proposed Changes:}{25}{subsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Distillation Through Attention}{25}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Previous Works:}{25}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Proposed Changes:}{26}{subsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Smaller and More Efficient Models (DeiT-S and DeiT-Ti)}{26}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Previous Works:}{26}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Proposed Changes:}{26}{subsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Performance and Efficiency Gains}{27}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Previous Works:}{27}{subsection.4.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Proposed Changes:}{27}{subsection.4.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Transfer Learning and Generalization}{27}{section.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Previous Works:}{28}{subsection.4.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}Proposed Changes:}{28}{subsection.4.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Results and Improvements}{28}{section.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Competitive Performance with Smaller Datasets}{28}{subsection.4.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Distillation Through Attention Enhances Model Performance}{29}{subsection.4.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}Improved Throughput and Computational Efficiency}{29}{subsection.4.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.4}Smaller Models with Comparable Accuracy}{29}{subsection.4.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.5}Transfer Learning and Generalization}{30}{subsection.4.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.6}Training Time Reduction}{30}{subsection.4.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.7}Distillation from CNNs Is More Effective than from Transformers}{30}{subsection.4.6.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Overall Improvements}{31}{section.4.7}\protected@file@percent }
\citation{DBLP:journals/corr/abs-2103-17239}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Going deeper with Image Transformers \cite  {DBLP:journals/corr/abs-2103-17239}}{32}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Key Ideas:}{32}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Deeper Vision Transformers (ViTs):}{32}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Class-Attention Mechanism:}{32}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Distillation with Class-Attention:}{32}{subsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.4}Efficient Training and Generalization:}{33}{subsection.5.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.5}Performance on Benchmarks:}{33}{subsection.5.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Results and Improvements}{33}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Performance Improvement with Depth}{33}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Introduction of Class-Attention Layers}{33}{subsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Hard-Label Distillation for Faster Convergence}{34}{subsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}Training Efficiency and Generalization}{34}{subsection.5.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.5}Benchmark Results and Competitive Performance}{34}{subsection.5.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.6}Improved Attention Mechanism for Class Prediction}{35}{subsection.5.2.6}\protected@file@percent }
\citation{DBLP:journals/corr/VaswaniSPUJGKP17}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Attention is All you need \cite  {DBLP:journals/corr/VaswaniSPUJGKP17}}{36}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Transformer Architecture:}{36}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Self-Attention and Multi-Head Attention:}{36}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Positional Encoding:}{37}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Advantages of Transformers:}{37}{section.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Results:}{37}{section.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Summary}{37}{section.6.6}\protected@file@percent }
\citation{DBLP:journals/corr/abs-2102-11126}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Deepfake Video Detection Using Convolutional Vision Transformer \cite  {DBLP:journals/corr/abs-2102-11126}}{38}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Key Components of the Model}{38}{section.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Feature Learning through CNNs:}{38}{subsection.7.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}Global Feature Understanding through ViTs:}{38}{subsection.7.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.3}Comprehensive Data Preprocessing:}{39}{subsection.7.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.4}Testing and Results:}{39}{subsection.7.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Results and Improvements}{39}{section.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.1}High Accuracy in Deepfake Detection}{39}{subsection.7.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.2}AUC and Loss Metrics}{39}{subsection.7.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.3}Combination of CNN and ViT for Local and Global Feature Learning}{39}{subsection.7.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.4}Generalized Model for Different Deepfake Scenarios}{40}{subsection.7.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.5}Comparison with Other Models}{40}{subsection.7.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.6}Data Preprocessing and Face Extraction}{40}{subsection.7.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.7}Future Improvements and Expansion}{41}{subsection.7.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Summary of Improvements:}{41}{section.7.3}\protected@file@percent }
\citation{DBLP:journals/corr/abs-2104-08500}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Visual Transformer Pruning \cite  {DBLP:journals/corr/abs-2104-08500}}{42}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Key Components of the Approach}{42}{section.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Results and Improvements}{43}{section.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.1}Significant Reduction in Parameters and Computation Costs}{43}{subsection.8.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.2}Maintaining High Accuracy with Minimal Loss}{43}{subsection.8.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.3}Effectiveness on Large Datasets}{44}{subsection.8.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.4}Flexibility of Pruning Rates}{44}{subsection.8.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.5}Simplicity and Efficiency of the Pruning Process}{44}{subsection.8.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.6}Promising Future Improvements}{45}{subsection.8.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Overall Improvements:}{45}{section.8.3}\protected@file@percent }
\citation{zhu2024scalablematmulfreelanguagemodeling}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Scalable MatMul-free Language Modeling \cite  {zhu2024scalablematmulfreelanguagemodeling}}{46}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Key Contributions}{46}{section.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.1}Bitlinear Layers:}{46}{subsection.9.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.2}Ternary Weights:}{46}{subsection.9.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.3}Scalability and Efficiency:}{47}{subsection.9.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.4}Experimental Results:}{47}{subsection.9.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Results and Improvements}{47}{section.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.1}Reduction in Computational Complexity}{47}{subsection.9.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.2}Memory Efficiency}{47}{subsection.9.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.3}Comparable Performance with Traditional Models}{47}{subsection.9.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.4}Faster Inference Times}{48}{subsection.9.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.5}Scalability Across Model Sizes}{48}{subsection.9.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.6}Potential for Further Optimization Through Quantization}{48}{subsection.9.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.7}Wider Applicability Beyond Language Modeling}{49}{subsection.9.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.3}Overall Improvements:}{49}{section.9.3}\protected@file@percent }
\citation{zhu2024spikegptgenerativepretrainedlanguage}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks \cite  {zhu2024spikegptgenerativepretrainedlanguage}}{50}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{DBLP:journals/corr/abs-2104-01353}
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Deepfake Detection Scheme Based on Vision Transformer and Distillation \cite  {DBLP:journals/corr/abs-2104-01353}}{51}{chapter.11}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {11.1}Main Components}{51}{section.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1.1}Vision Transformer and EfficientNet Combination:}{51}{subsection.11.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1.2}Distillation Token:}{52}{subsection.11.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1.3}Performance Comparison:}{52}{subsection.11.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.2}Results and Improvements}{52}{section.11.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.1}Higher Accuracy and Better Performance Metrics}{52}{subsection.11.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.2}Improved Deepfake Detection Robustness}{52}{subsection.11.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.3}Reduction in False Negatives (Improved Detection of Fake Videos)}{53}{subsection.11.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.4}Distillation Token for Better Generalization}{53}{subsection.11.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.5}Clearer Prediction of Fake Videos}{53}{subsection.11.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.6}Better Loss Reduction in Training}{54}{subsection.11.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.3}Overall Improvements:}{54}{section.11.3}\protected@file@percent }
\citation{DBLP:journals/corr/abs-1812-08685}
\@writefile{toc}{\contentsline {chapter}{\numberline {12}DeepFakes: a New Threat to Face Recognition? Assessment and Detection \cite  {DBLP:journals/corr/abs-1812-08685}}{55}{chapter.12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {12.1}Deepfake Video Generation:}{55}{section.12.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.2}Vulnerability of Face Recognition Systems:}{55}{section.12.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.3}Deepfake Detection Methods:}{56}{section.12.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.4}Challenges for Detection Systems:}{56}{section.12.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.5}Results and Improvements}{56}{section.12.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.5.1}Vulnerability of Face Recognition Systems}{56}{subsection.12.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.5.2}Creation of a Public Deepfake Database}{56}{subsection.12.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.5.3}Deepfake Detection Methods}{57}{subsection.12.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.5.4}Performance on Low-Quality vs. High-Quality Deepfakes}{57}{subsection.12.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.5.5}Improvements for Future Detection Systems}{57}{subsection.12.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.6}Overall Results and Improvements:}{58}{section.12.6}\protected@file@percent }
\citation{maass1997networks}
\@writefile{toc}{\contentsline {chapter}{\numberline {13}Networks of spiking neurons: The third generation of neural network models \cite  {maass1997networks}}{59}{chapter.13}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{DBLP:journals/corr/abs-2004-07532}
\@writefile{toc}{\contentsline {chapter}{\numberline {14}DeepFakes Evolution: Analysis of Facial Regions and Fake Detection Performance \cite  {DBLP:journals/corr/abs-2004-07532}}{60}{chapter.14}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {14.1}Key Idea}{60}{section.14.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.2}Key Contributions}{60}{section.14.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.3}Results and Improvements}{61}{section.14.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.1}Improved Detection Using Facial Region Analysis}{61}{subsection.14.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.2}Comparison of First and Second Generation Deepfakes}{61}{subsection.14.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.3}Importance of Facial Artifacts in Detection}{62}{subsection.14.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.4}Challenges with High-Quality Deepfakes}{62}{subsection.14.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.5}Benchmarking and Dataset Evaluation}{62}{subsection.14.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.4}Overall Results and Improvements}{62}{section.14.4}\protected@file@percent }
\bibstyle{IEEEtran}
\bibdata{refs}
\bibcite{le2023binaryvit}{1}
\bibcite{DBLP:journals/corr/abs-2112-13492}{2}
\bibcite{DBLP:journals/corr/abs-2106-10270}{3}
\bibcite{DBLP:journals/corr/abs-2012-12877}{4}
\bibcite{DBLP:journals/corr/abs-2103-17239}{5}
\bibcite{DBLP:journals/corr/VaswaniSPUJGKP17}{6}
\bibcite{DBLP:journals/corr/abs-2102-11126}{7}
\bibcite{DBLP:journals/corr/abs-2104-08500}{8}
\bibcite{zhu2024scalablematmulfreelanguagemodeling}{9}
\bibcite{zhu2024spikegptgenerativepretrainedlanguage}{10}
\bibcite{DBLP:journals/corr/abs-2104-01353}{11}
\bibcite{DBLP:journals/corr/abs-1812-08685}{12}
\bibcite{maass1997networks}{13}
\bibcite{DBLP:journals/corr/abs-2004-07532}{14}
\gdef \@abspage@last{66}
