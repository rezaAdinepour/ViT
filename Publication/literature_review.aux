\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\citation{le2023binaryvit}
\citation{DBLP:journals/corr/abs-2112-13492}
\HyPL@Entry{1<</S/D>>}
\citation{DBLP:journals/corr/abs-2106-10270}
\citation{DBLP:journals/corr/abs-2012-12877}
\citation{DBLP:journals/corr/abs-2103-17239}
\citation{DBLP:journals/corr/VaswaniSPUJGKP17}
\citation{DBLP:journals/corr/abs-2102-11126}
\citation{DBLP:journals/corr/abs-2104-08500}
\citation{zhu2024scalablematmulfreelanguagemodeling}
\citation{zhu2024spikegptgenerativepretrainedlanguage}
\citation{DBLP:journals/corr/abs-2104-01353}
\citation{DBLP:journals/corr/abs-1812-08685}
\citation{maass1997networks}
\citation{DBLP:journals/corr/abs-2004-07532}
\citation{DBLP:journals/corr/abs-1811-00661}
\citation{thing2023deepfakedetectiondeeplearning}
\citation{Zhang_2016}
\citation{le2023binaryvit}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}BinaryViT \cite  {le2023binaryvit}}{7}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introduction}{7}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Proposed Model}{7}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Global Average Pooling Layer}{7}{subsection.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Multiple Pooling Branches}{8}{subsection.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Affine Transformation Before Residual Connections}{8}{subsection.1.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}Pyramid Structure}{8}{subsection.1.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.5}Binary Fully-Connected Layers with Enhanced Attention}{9}{subsection.1.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.6}Distillation from Full-Precision Models}{9}{subsection.1.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Impact of the Changes}{9}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Results and Improvements}{10}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Performance Improvement on ImageNet-1k}{10}{subsection.1.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Efficiency in Terms of Operations and Parameters}{10}{subsection.1.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.3}Comparisons with State-of-the-Art (SOTA) Binary Models}{11}{subsection.1.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.4}Impact of Architectural Enhancements}{11}{subsection.1.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.5}Reduction in Computational Complexity}{11}{subsection.1.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Comparison Between Full-Precision and Binary Versions}{12}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Overall Improvements}{12}{section.1.5}\protected@file@percent }
\citation{DBLP:journals/corr/abs-2112-13492}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Vision Transformer for Small-Size Datasets \cite  {DBLP:journals/corr/abs-2112-13492}}{13}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Shifted Patch Tokenization (SPT)}{13}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Previous Approach:}{13}{subsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Proposed Change:}{14}{subsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Locality Self-Attention (LSA)}{14}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Previous Approach:}{14}{subsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Proposed Change:}{14}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Comparison to Other Data-Efficient ViTs}{15}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Efficiency vs. Performance Trade-offs}{16}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Previous Models:}{16}{subsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Proposed Model:}{16}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Performance Gains}{16}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Overall Impact of the Proposed Changes}{16}{section.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Results and Improvements}{17}{section.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}Performance Improvements on Small Datasets}{17}{subsection.2.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.2}Improvements in ImageNet Performance}{17}{subsection.2.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.3}Efficiency and Computational Overhead}{17}{subsection.2.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.4}Ablation Study Results}{18}{subsection.2.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.5}Qualitative Improvements}{18}{subsection.2.7.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.6}Comparison with State-of-the-Art (SOTA) Models}{18}{subsection.2.7.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Key Takeaways:}{19}{section.2.8}\protected@file@percent }
\citation{DBLP:journals/corr/abs-2106-10270}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers \cite  {DBLP:journals/corr/abs-2106-10270}}{20}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Data Augmentation and Regularization ("AugReg")}{20}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Previous Works:}{20}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Proposed Changes}{21}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Trade-offs Between Data, Augmentation, and Compute Budget}{21}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Previous Works:}{21}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Proposed Changes:}{21}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Regularization Techniques and Their Impact}{22}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Previous Works:}{22}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Proposed Changes:}{22}{subsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Impact of Model Size}{22}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Previous Works:}{22}{subsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Proposed Changes:}{22}{subsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Pre-training and Transfer Learning}{23}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Previous Works:}{23}{subsection.3.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Proposed Changes:}{23}{subsection.3.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Practical Recommendations}{23}{section.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Overall Impact of Changes}{23}{section.3.7}\protected@file@percent }
\citation{DBLP:journals/corr/abs-2012-12877}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Training data-efficient image transformers \& distillation through attention \cite  {DBLP:journals/corr/abs-2012-12877}}{25}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Data-Efficient Image Transformers (DeiT)}{25}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Previous Works:}{25}{subsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Proposed Changes:}{26}{subsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Distillation Through Attention}{26}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Previous Works:}{26}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Proposed Changes:}{27}{subsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Smaller and More Efficient Models (DeiT-S and DeiT-Ti)}{27}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Previous Works:}{27}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Proposed Changes:}{27}{subsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Performance and Efficiency Gains}{28}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Previous Works:}{28}{subsection.4.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Proposed Changes:}{28}{subsection.4.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Transfer Learning and Generalization}{28}{section.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Previous Works:}{29}{subsection.4.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}Proposed Changes:}{29}{subsection.4.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Results and Improvements}{29}{section.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Competitive Performance with Smaller Datasets}{29}{subsection.4.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Distillation Through Attention Enhances Model Performance}{30}{subsection.4.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}Improved Throughput and Computational Efficiency}{30}{subsection.4.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.4}Smaller Models with Comparable Accuracy}{30}{subsection.4.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.5}Transfer Learning and Generalization}{31}{subsection.4.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.6}Training Time Reduction}{31}{subsection.4.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.7}Distillation from CNNs Is More Effective than from Transformers}{31}{subsection.4.6.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Overall Improvements}{32}{section.4.7}\protected@file@percent }
\citation{DBLP:journals/corr/abs-2103-17239}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Going deeper with Image Transformers \cite  {DBLP:journals/corr/abs-2103-17239}}{33}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Key Ideas:}{33}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Deeper Vision Transformers (ViTs):}{33}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Class-Attention Mechanism:}{33}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Distillation with Class-Attention:}{33}{subsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.4}Efficient Training and Generalization:}{34}{subsection.5.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.5}Performance on Benchmarks:}{34}{subsection.5.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Results and Improvements}{34}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Performance Improvement with Depth}{34}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Introduction of Class-Attention Layers}{34}{subsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Hard-Label Distillation for Faster Convergence}{35}{subsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}Training Efficiency and Generalization}{35}{subsection.5.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.5}Benchmark Results and Competitive Performance}{35}{subsection.5.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.6}Improved Attention Mechanism for Class Prediction}{36}{subsection.5.2.6}\protected@file@percent }
\citation{DBLP:journals/corr/VaswaniSPUJGKP17}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Attention is All you need \cite  {DBLP:journals/corr/VaswaniSPUJGKP17}}{37}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Transformer Architecture:}{37}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Self-Attention and Multi-Head Attention:}{37}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Positional Encoding:}{38}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Advantages of Transformers:}{38}{section.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Results:}{38}{section.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Summary}{38}{section.6.6}\protected@file@percent }
\citation{DBLP:journals/corr/abs-2102-11126}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Deepfake Video Detection Using Convolutional Vision Transformer \cite  {DBLP:journals/corr/abs-2102-11126}}{39}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Key Components of the Model}{39}{section.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Feature Learning through CNNs:}{39}{subsection.7.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}Global Feature Understanding through ViTs:}{39}{subsection.7.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.3}Comprehensive Data Preprocessing:}{40}{subsection.7.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.4}Testing and Results:}{40}{subsection.7.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Results and Improvements}{40}{section.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.1}High Accuracy in Deepfake Detection}{40}{subsection.7.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.2}AUC and Loss Metrics}{40}{subsection.7.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.3}Combination of CNN and ViT for Local and Global Feature Learning}{40}{subsection.7.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.4}Generalized Model for Different Deepfake Scenarios}{41}{subsection.7.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.5}Comparison with Other Models}{41}{subsection.7.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.6}Data Preprocessing and Face Extraction}{41}{subsection.7.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.7}Future Improvements and Expansion}{42}{subsection.7.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Summary of Improvements:}{42}{section.7.3}\protected@file@percent }
\citation{DBLP:journals/corr/abs-2104-08500}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Visual Transformer Pruning \cite  {DBLP:journals/corr/abs-2104-08500}}{43}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Key Components of the Approach}{43}{section.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Results and Improvements}{44}{section.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.1}Significant Reduction in Parameters and Computation Costs}{44}{subsection.8.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.2}Maintaining High Accuracy with Minimal Loss}{44}{subsection.8.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.3}Effectiveness on Large Datasets}{45}{subsection.8.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.4}Flexibility of Pruning Rates}{45}{subsection.8.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.5}Simplicity and Efficiency of the Pruning Process}{45}{subsection.8.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.6}Promising Future Improvements}{46}{subsection.8.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Overall Improvements:}{46}{section.8.3}\protected@file@percent }
\citation{zhu2024scalablematmulfreelanguagemodeling}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Scalable MatMul-free Language Modeling \cite  {zhu2024scalablematmulfreelanguagemodeling}}{47}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Key Contributions}{47}{section.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.1}Bitlinear Layers:}{47}{subsection.9.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.2}Ternary Weights:}{47}{subsection.9.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.3}Scalability and Efficiency:}{48}{subsection.9.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.4}Experimental Results:}{48}{subsection.9.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Results and Improvements}{48}{section.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.1}Reduction in Computational Complexity}{48}{subsection.9.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.2}Memory Efficiency}{48}{subsection.9.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.3}Comparable Performance with Traditional Models}{48}{subsection.9.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.4}Faster Inference Times}{49}{subsection.9.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.5}Scalability Across Model Sizes}{49}{subsection.9.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.6}Potential for Further Optimization Through Quantization}{49}{subsection.9.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.7}Wider Applicability Beyond Language Modeling}{50}{subsection.9.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.3}Overall Improvements:}{50}{section.9.3}\protected@file@percent }
\citation{zhu2024spikegptgenerativepretrainedlanguage}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks \cite  {zhu2024spikegptgenerativepretrainedlanguage}}{51}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{DBLP:journals/corr/abs-2104-01353}
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Deepfake Detection Scheme Based on Vision Transformer and Distillation \cite  {DBLP:journals/corr/abs-2104-01353}}{52}{chapter.11}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {11.1}Main Components}{52}{section.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1.1}Vision Transformer and EfficientNet Combination:}{52}{subsection.11.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1.2}Distillation Token:}{53}{subsection.11.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1.3}Performance Comparison:}{53}{subsection.11.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.2}Results and Improvements}{53}{section.11.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.1}Higher Accuracy and Better Performance Metrics}{53}{subsection.11.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.2}Improved Deepfake Detection Robustness}{53}{subsection.11.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.3}Reduction in False Negatives (Improved Detection of Fake Videos)}{54}{subsection.11.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.4}Distillation Token for Better Generalization}{54}{subsection.11.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.5}Clearer Prediction of Fake Videos}{54}{subsection.11.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.6}Better Loss Reduction in Training}{55}{subsection.11.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11.3}Overall Improvements:}{55}{section.11.3}\protected@file@percent }
\citation{DBLP:journals/corr/abs-1812-08685}
\@writefile{toc}{\contentsline {chapter}{\numberline {12}DeepFakes: a New Threat to Face Recognition? Assessment and Detection \cite  {DBLP:journals/corr/abs-1812-08685}}{56}{chapter.12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {12.1}Deepfake Video Generation:}{56}{section.12.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.2}Vulnerability of Face Recognition Systems:}{56}{section.12.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.3}Deepfake Detection Methods:}{57}{section.12.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.4}Challenges for Detection Systems:}{57}{section.12.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.5}Results and Improvements}{57}{section.12.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.5.1}Vulnerability of Face Recognition Systems}{57}{subsection.12.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.5.2}Creation of a Public Deepfake Database}{57}{subsection.12.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.5.3}Deepfake Detection Methods}{58}{subsection.12.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.5.4}Performance on Low-Quality vs. High-Quality Deepfakes}{58}{subsection.12.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.5.5}Improvements for Future Detection Systems}{58}{subsection.12.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12.6}Overall Results and Improvements:}{59}{section.12.6}\protected@file@percent }
\citation{maass1997networks}
\@writefile{toc}{\contentsline {chapter}{\numberline {13}Networks of spiking neurons: The third generation of neural network models \cite  {maass1997networks}}{60}{chapter.13}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{DBLP:journals/corr/abs-2004-07532}
\@writefile{toc}{\contentsline {chapter}{\numberline {14}DeepFakes Evolution: Analysis of Facial Regions and Fake Detection Performance \cite  {DBLP:journals/corr/abs-2004-07532}}{61}{chapter.14}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {14.1}Key Idea}{61}{section.14.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.2}Key Contributions}{61}{section.14.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.3}Results and Improvements}{62}{section.14.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.1}Improved Detection Using Facial Region Analysis}{62}{subsection.14.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.2}Comparison of First and Second Generation Deepfakes}{62}{subsection.14.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.3}Importance of Facial Artifacts in Detection}{63}{subsection.14.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.4}Challenges with High-Quality Deepfakes}{63}{subsection.14.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.5}Benchmarking and Dataset Evaluation}{63}{subsection.14.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14.4}Overall Results and Improvements}{63}{section.14.4}\protected@file@percent }
\citation{DBLP:journals/corr/abs-1811-00661}
\@writefile{toc}{\contentsline {chapter}{\numberline {15}Exposing Deep Fakes Using Inconsistent Head Poses \cite  {DBLP:journals/corr/abs-1811-00661}}{65}{chapter.15}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {15.1}Method}{65}{section.15.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.2}Results and Improvements}{66}{section.15.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.2.1}Effective Detection of Deepfakes Using Head Pose Inconsistencies}{66}{subsection.15.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.2.2}High Detection Accuracy}{66}{subsection.15.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.2.3}Simplicity and Efficiency}{66}{subsection.15.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.2.4}Applicability Across Different Types of Deepfakes}{67}{subsection.15.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.2.5}Potential for Integration with Other Detection Techniques}{67}{subsection.15.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15.3}Overall Results and Improvements}{67}{section.15.3}\protected@file@percent }
\citation{thing2023deepfakedetectiondeeplearning}
\@writefile{toc}{\contentsline {chapter}{\numberline {16}Deepfake Detection with Deep Learning: Convolutional Neural Networks versus Transformers \cite  {thing2023deepfakedetectiondeeplearning}}{69}{chapter.16}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {16.1}Key Ideas}{69}{section.16.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {16.2}Key Findings:}{70}{section.16.2}\protected@file@percent }
\citation{Zhang_2016}
\@writefile{toc}{\contentsline {chapter}{\numberline {17}Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks \cite  {Zhang_2016}}{71}{chapter.17}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {17.1}Main Idea}{71}{section.17.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {17.2}Main Contributions}{72}{section.17.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {17.3}Results and Improvements}{72}{section.17.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {17.3.1}Improved Accuracy on Challenging Benchmarks}{72}{subsection.17.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {17.3.2}Joint Face Detection and Alignment Improves Both Tasks}{72}{subsection.17.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {17.3.3}Efficiency and Real-Time Performance}{73}{subsection.17.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {17.3.4}Online Hard Sample Mining}{73}{subsection.17.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {17.3.5}Lightweight CNN Architecture}{73}{subsection.17.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {17.3.6}Versatility Across Multiple Datasets}{74}{subsection.17.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {17.4}Overall Results and Improvements}{74}{section.17.4}\protected@file@percent }
\bibstyle{IEEEtran}
\bibdata{refs}
\bibcite{le2023binaryvit}{1}
\bibcite{DBLP:journals/corr/abs-2112-13492}{2}
\bibcite{DBLP:journals/corr/abs-2106-10270}{3}
\bibcite{DBLP:journals/corr/abs-2012-12877}{4}
\bibcite{DBLP:journals/corr/abs-2103-17239}{5}
\bibcite{DBLP:journals/corr/VaswaniSPUJGKP17}{6}
\bibcite{DBLP:journals/corr/abs-2102-11126}{7}
\bibcite{DBLP:journals/corr/abs-2104-08500}{8}
\bibcite{zhu2024scalablematmulfreelanguagemodeling}{9}
\bibcite{zhu2024spikegptgenerativepretrainedlanguage}{10}
\bibcite{DBLP:journals/corr/abs-2104-01353}{11}
\bibcite{DBLP:journals/corr/abs-1812-08685}{12}
\bibcite{maass1997networks}{13}
\bibcite{DBLP:journals/corr/abs-2004-07532}{14}
\bibcite{DBLP:journals/corr/abs-1811-00661}{15}
\bibcite{thing2023deepfakedetectiondeeplearning}{16}
\bibcite{Zhang_2016}{17}
\gdef \@abspage@last{77}
